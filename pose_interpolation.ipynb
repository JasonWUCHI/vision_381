{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import smplx\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from pytransform3d.rotations import (\n",
    "    quaternion_from_compact_axis_angle,\n",
    "    compact_axis_angle_from_quaternion,\n",
    "    quaternion_slerp,\n",
    ")\n",
    "\n",
    "NUM_BODY_JOINTS = 24\n",
    "\n",
    "def interpolate_smpl_poses(pose1, pose2, num_frames=10):\n",
    "    \"\"\"\n",
    "    Interpolates between two SMPL poses using SLERP.\n",
    "    Args:\n",
    "        pose1 (ndarray): The first pose in axis-angle of shape (NUM_BODY_JOINTS, 3)\n",
    "        pose2 (ndarray): The second pose in axis-angle of shape (NUM_BODY_JOINTS, 3)\n",
    "        num_frames (int): The number of frames to interpolate between.\n",
    "    Returns:\n",
    "        interpolated_poses (ndarray): The interpolated poses in axis-angle of shape (num_frames, NUM_BODY_JOINTS, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the poses are in the correct format\n",
    "    assert isinstance(pose1, np.ndarray) and isinstance(pose2, np.ndarray), \"Poses must be numpy arrays\"\n",
    "    assert pose1.shape == pose2.shape == (NUM_BODY_JOINTS, 3), f\"Pose shapes must be ({NUM_BODY_JOINTS}, 3)\"\n",
    "\n",
    "    interpolated_poses = np.zeros((NUM_BODY_JOINTS, num_frames, 3), dtype=np.float32)\n",
    "    for i in range(NUM_BODY_JOINTS):\n",
    "        quat1 = quaternion_from_compact_axis_angle(pose1[i])\n",
    "        quat2 = quaternion_from_compact_axis_angle(pose2[i])\n",
    "        interpolated_poses[i, 0] = pose1[i]\n",
    "        interpolated_poses[i, -1] = pose2[i]\n",
    "        for j in range(1, num_frames - 1):\n",
    "            t = j / (num_frames - 1)\n",
    "            interp_quat = quaternion_slerp(quat1, quat2, t)\n",
    "            interpolated_poses[i, j] = compact_axis_angle_from_quaternion(interp_quat)\n",
    "    return np.swapaxes(interpolated_poses, 0, 1)\n",
    "\n",
    "def render_pose_as_image(vertices, faces):\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "    mesh.compute_vertex_normals()\n",
    "    mesh.paint_uniform_color([0.3, 0.3, 0.3])\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(visible=False)\n",
    "    vis.add_geometry(mesh)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    ctr.set_lookat([0, 0, 0])\n",
    "    ctr.set_front([0, -1, 0])\n",
    "    ctr.set_up([0, 0, 1])\n",
    "    ctr.set_zoom(1)\n",
    "\n",
    "    image = vis.capture_screen_float_buffer(True)\n",
    "    vis.destroy_window()\n",
    "    return np.asarray(image)\n",
    "\n",
    "def save_video(frames, output_path=\"output.mp4\", fps=30):\n",
    "    assert frames.ndim == 4, \"Frames should be a 4D numpy array.\"\n",
    "    height, width = frames.shape[1:3]\n",
    "    is_color = frames.shape[-1] == 3\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'avc1')  # or 'XVID', 'avc1', etc.\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height), isColor=is_color)\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        if frame.shape[:2] != (height, width):\n",
    "            raise ValueError(f\"Frame {i} has mismatched size.\")\n",
    "        if is_color and frame.shape[2] != 3:\n",
    "            raise ValueError(f\"Frame {i} is not a 3-channel color image.\")\n",
    "        if not is_color and len(frame.shape) != 2:\n",
    "            raise ValueError(f\"Frame {i} is not a grayscale image.\")\n",
    "        writer.write(frame if is_color else cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "    writer.release()\n",
    "\n",
    "def render_pose_sequence_as_video(poses, smpl_model, output_path=\"output.mp4\", fps=30):\n",
    "    images = []\n",
    "    for pose in poses:\n",
    "        output = smpl_model(\n",
    "            global_orient=pose[None, :3],\n",
    "            body_pose=pose[None, 3:],\n",
    "            transl=None,\n",
    "            return_verts=True)\n",
    "        vertices = output.vertices.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        image = render_pose_as_image(vertices, smpl_model.faces)\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        images.append(image)\n",
    "    images = np.array(images)\n",
    "    save_video(images, output_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download the SMPL model go to [this](https://smpl.is.tue.mpg.de/) (male\n",
    "# and female models) and [this](https://smplify.is.tue.mpg.de/) (gender neutral\n",
    "# model) project website and register to get access to the downloads section.\n",
    "\n",
    "MODEL_PATH = \"smplx/models\"\n",
    "\n",
    "POSE1_PATH = \"wham_pose_30.pt\"\n",
    "POSE2_PATH = \"wham_pose_75_edited.pt\"\n",
    "POSE3_PATH = \"wham_pose_120.pt\"\n",
    "\n",
    "smpl_model = smplx.create(\n",
    "    model_path=MODEL_PATH,\n",
    "    model_type='smpl',\n",
    "    gender='neutral',\n",
    "    ext='npz')\n",
    "\n",
    "pose1 = torch.load(POSE1_PATH)\n",
    "pose2 = torch.load(POSE2_PATH)\n",
    "pose3 = torch.load(POSE3_PATH)\n",
    "\n",
    "pose1 = pose1[:, :72].reshape(NUM_BODY_JOINTS, 3).numpy()\n",
    "pose2 = pose2[None, :72].reshape(NUM_BODY_JOINTS, 3).numpy()\n",
    "pose3 = pose3[:, :72].reshape(NUM_BODY_JOINTS, 3).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose1_to_pose2 = interpolate_smpl_poses(pose1, pose2, num_frames=46)\n",
    "pose1_to_pose2 = pose1_to_pose2.reshape(-1, NUM_BODY_JOINTS * 3)\n",
    "pose1_to_pose2[:, (NUM_BODY_JOINTS - 2) * 3:] = 0.\n",
    "pose1_to_pose2 = torch.from_numpy(pose1_to_pose2)\n",
    "\n",
    "pose2_to_pose3 = interpolate_smpl_poses(pose2, pose3, num_frames=46)\n",
    "pose2_to_pose3 = pose2_to_pose3.reshape(-1, NUM_BODY_JOINTS * 3)\n",
    "pose2_to_pose3[:, (NUM_BODY_JOINTS - 2) * 3:] = 0.\n",
    "pose2_to_pose3 = torch.from_numpy(pose2_to_pose3)\n",
    "\n",
    "assert torch.all(pose1_to_pose2[-1] == pose2_to_pose3[0])\n",
    "pose1_to_pose3 = torch.zeros((91, 72), dtype=torch.float32)\n",
    "pose1_to_pose3[:46] = pose1_to_pose2\n",
    "pose1_to_pose3[45:] = pose2_to_pose3\n",
    "torch.save(pose1_to_pose3, \"pose1_to_pose3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_pose_sequence_as_video(pose1_to_pose3, smpl_model, output_path=\"pose1_to_pose3.mp4\", fps=30)\n",
    "print(\"Video saved to pose1_to_pose3.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
